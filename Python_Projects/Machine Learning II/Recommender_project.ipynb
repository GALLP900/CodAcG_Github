{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            user_id   book_id  \\\n",
      "0  d089c9b670c0b0b339353aebbace46a1   7686667   \n",
      "1  6dcb2c16e12a41ae0c6c38e9d46f3292  18073066   \n",
      "2  244e0ce681148a7586d7746676093ce9  13610986   \n",
      "3  73fcc25ff29f8b73b3a7578aec846394  27274343   \n",
      "4  f8880e158a163388a990b64fec7df300  11614718   \n",
      "\n",
      "                          review_id  rating  \\\n",
      "0  3337e0e75701f7f682de11638ccdc60c       3   \n",
      "1  7201aa3c1161f2bad81258b6d4686c16       5   \n",
      "2  07a203f87bfe1b65ff58774667f6f80d       5   \n",
      "3  8be2d87b07098c16f9742020ec459383       1   \n",
      "4  a29c4ba03e33ad073a414ac775266c5f       4   \n",
      "\n",
      "                                         review_text  \\\n",
      "0  Like Matched, this book felt like it was echoi...   \n",
      "1  WOW again! 4,5 Stars \\r\\n So i wont forget to ...   \n",
      "2  The second novel was hot & heavy. Not only in ...   \n",
      "3  What a maddening waste of time. And I unfortun...   \n",
      "4  4.5 stars! \\r\\n This was an awesome read! \\r\\n...   \n",
      "\n",
      "                       date_added                    date_updated  \\\n",
      "0  Fri Apr 29 14:45:32 -0700 2011  Mon Feb 02 12:57:57 -0800 2015   \n",
      "1  Thu Aug 01 02:15:18 -0700 2013  Mon Nov 18 14:49:26 -0800 2013   \n",
      "2  Sun Nov 23 18:17:50 -0800 2014  Sat May 16 20:34:19 -0700 2015   \n",
      "3  Mon Oct 31 08:29:06 -0700 2016  Wed Apr 26 16:06:28 -0700 2017   \n",
      "4  Tue Mar 26 10:55:30 -0700 2013  Mon Sep 08 09:57:05 -0700 2014   \n",
      "\n",
      "                          read_at                      started_at  n_votes  \\\n",
      "0  Sat Jun 18 00:00:00 -0700 2011  Thu May 19 00:00:00 -0700 2011        0   \n",
      "1  Mon Aug 19 00:00:00 -0700 2013  Mon Aug 12 00:00:00 -0700 2013       16   \n",
      "2  Fri Dec 19 00:00:00 -0800 2014  Sun Nov 23 00:00:00 -0800 2014        0   \n",
      "3  Wed Apr 26 16:06:28 -0700 2017  Sun Apr 23 00:00:00 -0700 2017        0   \n",
      "4  Sun Apr 20 09:26:41 -0700 2014  Fri Apr 18 00:00:00 -0700 2014        0   \n",
      "\n",
      "   n_comments  \n",
      "0           0  \n",
      "1          14  \n",
      "2           0  \n",
      "3           1  \n",
      "4           0  \n",
      "            book_id       rating      n_votes   n_comments\n",
      "count  3.500000e+03  3500.000000  3500.000000  3500.000000\n",
      "mean   1.314011e+07     3.686000     3.038857     0.754286\n",
      "std    9.143899e+06     1.251911    15.508018     3.474921\n",
      "min    1.000000e+00     0.000000     0.000000     0.000000\n",
      "25%    6.380978e+06     3.000000     0.000000     0.000000\n",
      "50%    1.320679e+07     4.000000     0.000000     0.000000\n",
      "75%    1.928702e+07     5.000000     1.000000     0.000000\n",
      "max    3.589888e+07     5.000000   431.000000    77.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3500 entries, 0 to 3499\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   user_id       3500 non-null   object\n",
      " 1   book_id       3500 non-null   int64 \n",
      " 2   review_id     3500 non-null   object\n",
      " 3   rating        3500 non-null   int64 \n",
      " 4   review_text   3500 non-null   object\n",
      " 5   date_added    3500 non-null   object\n",
      " 6   date_updated  3500 non-null   object\n",
      " 7   read_at       3167 non-null   object\n",
      " 8   started_at    2395 non-null   object\n",
      " 9   n_votes       3500 non-null   int64 \n",
      " 10  n_comments    3500 non-null   int64 \n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 300.9+ KB\n",
      "None\n",
      "rating\n",
      "4    1278\n",
      "5    1001\n",
      "3     707\n",
      "2     269\n",
      "1     125\n",
      "0     120\n",
      "Name: count, dtype: int64\n",
      "rating\n",
      "4    1278\n",
      "5    1001\n",
      "3     707\n",
      "2     269\n",
      "1     125\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from surprise import Reader \n",
    "book_ratings = pd.read_csv('goodreads_ratings.csv') \n",
    "print(book_ratings.head()) \n",
    "\n",
    "#1. Print dataset size and examine column data types \n",
    "print(book_ratings.describe()) \n",
    "print(book_ratings.info()) \n",
    "\n",
    "#2. Distribution of ratings \n",
    "print(book_ratings.rating.value_counts()) \n",
    "\n",
    "#3. Filter ratings that are out of range \n",
    "book_ratings = book_ratings[book_ratings['rating']!=0] \n",
    "print(book_ratings.rating.value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1105\n",
      "3.8250739644970415\n"
     ]
    }
   ],
   "source": [
    "#4. Prepare data for surprise: build a Suprise reader object \n",
    "from surprise import Reader \n",
    "reader = Reader(rating_scale=(1, 5)) \n",
    "\n",
    "#5. Load book_ratings into a Surprise Dataset \n",
    "from surprise import Dataset \n",
    "Surprise = Dataset.load_from_df(book_ratings[['user_id', 'book_id', 'rating']], reader) \n",
    "\n",
    "#6. Create a 80:20 train-test split and set the random state to 7 \n",
    "from surprise.model_selection import train_test_split \n",
    "trainset,testset = train_test_split(Surprise,test_size=0.2,random_state=7) \n",
    "\n",
    "#7. Use KNNBasice from Surprise to train a collaborative filter \n",
    "from surprise import KNNBasic \n",
    "recommender = KNNBasic() \n",
    "recommender.fit(trainset) \n",
    "\n",
    "#8. Evaluate the recommender system \n",
    "from surprise import accuracy \n",
    "predictions = recommender.test(testset) \n",
    "accuracy.rmse(predictions) \n",
    "\n",
    "#9. Prediction on a user who gave the \"The Three-Body Problem\" a rating of 5 \n",
    "print(recommender.predict('8842281e1d1347389f2ab93d60773d4d', '18007564').est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1105\n",
      "For k=10, RMSE: 1.110471008157185, Prediction: 3.8250739644970415\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1105\n",
      "For k=20, RMSE: 1.110471008157185, Prediction: 3.8250739644970415\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 1.1105\n",
      "For k=40, RMSE: 1.110471008157185, Prediction: 3.8250739644970415\n"
     ]
    }
   ],
   "source": [
    "#10. Tuning hyperparameters\n",
    "k_params = [10,20,40]\n",
    "rmse_results = {}\n",
    "predictions_results = {}\n",
    "\n",
    "for i in k_params:\n",
    "    recommender_2 = KNNBasic(k=i)\n",
    "    recommender_2.fit(trainset)\n",
    "    predictions_2 = recommender_2.test(testset) \n",
    "    rmse_results[i] = accuracy.rmse(predictions_2)\n",
    "    predictions_results[i] = recommender_2.predict('8842281e1d1347389f2ab93d60773d4d', '18007564').est\n",
    "    print(f\"For k={i}, RMSE: {rmse_results[i]}, Prediction: {predictions_results[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
